{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7388094-4e32-4c7d-9b84-1a92bfcf7017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from utils.model_selection import train_val_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a31d5-1a5e-4000-b184-b5c081aa795c",
   "metadata": {},
   "source": [
    "# Get and save training, val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8521f6-4d32-4f91-a9e1-6c6a49e80ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_save_data(path='data/raw/Google-Playstore.csv', chunksize=100000, target=\"Rating\",\n",
    "                      val_size = 0.15, test_size=0.15,\n",
    "                      random_state=42, save_path_prefix='google_playstore'):\n",
    "    '''\n",
    "    Loads the raw data. Splits it into training, validation and test sets and incrementally saves them \n",
    "    by appending each chunk to a CSV file at the specified location.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        success = 0\n",
    "        chunks = pd.read_csv(path, chunksize=chunksize)\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        results = []\n",
    "        for chunk in chunks:\n",
    "            f = pool.apply_async(train_val_test_split, args=(chunk, val_size, test_size, random_state)) # asynchronously applying function to chunk\n",
    "            results.append(f) # appending result to results\n",
    "\n",
    "        chunks = pd.read_csv(path, chunksize=chunksize)\n",
    "        first_chunk = True\n",
    "        \n",
    "        for f, chunk in zip(results, chunks):\n",
    "            train_idx, val_idx, test_idx = f.get(timeout=120)\n",
    "            \n",
    "            train_chunk = chunk.loc[train_idx, :].copy() # getting output of each parallel job\n",
    "            y_train = train_chunk[target].fillna(0)\n",
    "            x_train = train_chunk.drop(columns=target)\n",
    "            \n",
    "            \n",
    "            val_chunk = chunk.loc[val_idx, :].copy() # getting output of each parallel job\n",
    "            y_val = val_chunk[target].fillna(0)\n",
    "            x_val = val_chunk.drop(columns=target)\n",
    "            \n",
    "            \n",
    "            test_chunk = chunk.loc[test_idx, :].copy() # getting output of each parallel job\n",
    "            y_test = test_chunk[target].fillna(0)\n",
    "            x_test = test_chunk.drop(columns=target)\n",
    "            \n",
    "            if first_chunk == True :\n",
    "                x_train.to_csv(f'data/raw/x_{save_path_prefix}_train.csv', index=False)\n",
    "                y_train.to_csv(f'data/raw/y_{save_path_prefix}_train.csv', index=False)\n",
    "                \n",
    "                x_val.to_csv(f'data/raw/x_{save_path_prefix}_val.csv', index=False)\n",
    "                y_val.to_csv(f'data/raw/y_{save_path_prefix}_val.csv', index=False)\n",
    "                \n",
    "                x_test.to_csv(f'data/raw/x_{save_path_prefix}_test.csv', index=False)\n",
    "                y_test.to_csv(f'data/raw/y_{save_path_prefix}_test.csv', index=False)\n",
    "                \n",
    "                first_chunk = False\n",
    "            else:\n",
    "                x_train.to_csv(f'data/raw/x_{save_path_prefix}_train.csv', mode=\"a\", header=False, index=False)\n",
    "                y_train.to_csv(f'data/raw/y_{save_path_prefix}_train.csv', mode=\"a\", header=False, index=False)\n",
    "                \n",
    "                x_val.to_csv(f'data/raw/x_{save_path_prefix}_val.csv', mode=\"a\", header=False, index=False)\n",
    "                y_val.to_csv(f'data/raw/y_{save_path_prefix}_val.csv', mode=\"a\", header=False, index=False)\n",
    "                \n",
    "                x_test.to_csv(f'data/raw/x_{save_path_prefix}_test.csv', mode=\"a\", header=False, index=False)\n",
    "                y_test.to_csv(f'data/raw/y_{save_path_prefix}_test.csv', mode=\"a\", header=False, index=False)\n",
    "                \n",
    "    except:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        success = 0\n",
    "        raise\n",
    "    else:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        success = 1\n",
    "    \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073aae72-87af-4d99-aa7d-2af1b1e6668f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = get_and_save_data()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79793246-57df-44b0-9e6c-ea9c281bd27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
